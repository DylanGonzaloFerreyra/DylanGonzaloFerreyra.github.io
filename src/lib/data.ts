export const personalInfo = {
  name: "Dylan Ferreyra",
  location: "Buenos Aires, Argentina",
  email: "dylanferreyra006@gmail.com",
  github: "https://github.com/DylanGonzaloFerreyra",
  linkedin: "https://www.linkedin.com/in/dylan-ferreyra-95698834a?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app",
};

export const education = [
  {
    institution: "San Vicente de Paul Technical School",
    location: "La Plata, Buenos Aires",
    degree: "High School Diploma - Electronics Technician",
    period: "Feb 2019 - Nov 2025",
  },
];
export const certificates = [
  {
    title: "Python",
    description: "Certificate of CS50's Introduction to Programming with Python.",
    imageUrl: "certificates/CS50P_PYTHON.jpg",
    link: "https://certificates.cs50.io/bca18fcf-a55c-42f1-96ce-911e7ab2e8fa.pdf?size=letter",
  },
  {
    title: "SQL",
    description: "Certificate of CS50's introduction to Databases with SQL.",
    imageUrl: "certificates/CS50_SQL.jpg",
    link: "https://cs50.harvard.edu/certificates/99ff6a4a-48a5-42c0-85ec-ca3994134042",
  },
  {
    title: "Big Data",
    description: "Certificate of IBM's Big Data.",
    imageUrl: "certificates/big_data.jpg",
    link: "https://courses.cognitiveclass.ai/certificates/055e188dc2094198b9bce7fada35bc7c",
  },
  {
    title: "Data Science 101",
    description: "Certificate of IBM's Data Science 101.",
    imageUrl: "certificates/DataScience.jpg",
    link: "https://courses.cognitiveclass.ai/certificates/44f020c40a0f4b0fa58b12bd48d27caa",
  },
  {
    title: "Data Science Methodology",
    description: "Certificate of IBM's Data Science Methodology.",
    imageUrl: "certificates/Methodology.jpg",
    link: "https://courses.cognitiveclass.ai/certificates/44bbe2dd450b436997739b70b75530e3",
  },
  {
    title: "AWS Cloud Practitioner",
    description: "Certificate of AWS Cloud Practitioner.",
    imageUrl: "certificates/udemy_AWS_Certified_Cloud_Practitioner.jpg",
    link: "https://udemy-certificate.s3.amazonaws.com/pdf/UC-7dd03ee4-a8b3-41bc-bb54-20e2997df460.pdf",
  }
  
];



export const skills = {
  programmingLanguages: [
    "Python",
    "SQL",
  ],
  frontendDevelopment: [],
  backendDevelopment: ["Nodejs", "Expressjs"],
  databaseAndStorage: ["PostgreSQL", "MySQL", "SQLite", "MongoDB"],
  cloudAndDevOps: ["AWS"],
  dataVisualization: ["Power BI", "Tableau"], 
  toolsAndServices: ["dbt (Data Build Tool)", "Apache Airflow", "Apache Spark", "Snowflake", "Pandas"],
};

export const projects = [
  {
    title: "Fictional store Dashboard",
    github: "https://github.com/DylanGonFer/Fictional-store-Dashboard/tree/main",
    imageUrl: "project_covers/Fictional-store-Dashboard.png",
    description: "Fake Store Dashboard created using Power BI and enriched with data generated in Python using Faker library.",
  },
  {
    title: "Music Streaming Preference Analysis",
    github: "https://github.com/DylanGonzaloFerreyra/Music-Streaming-Preferences-Dashboard/tree/main",
    imageUrl: "project_covers/Music-Streaming-Preference-Analysis.png",
    description: "This repository contains an analysis of listener preferences on music platforms around the world. Python (Pandas) was used for data cleaning, and Power BI was used to create an interactive dashboard.",
  },
  {
    title: "Meteorology Pipeline",
    github: "https://github.com/DylanGonzaloFerreyra/Meteorology-Pipeline",
    imageUrl: "project_covers/MeteorologyPipeline.jpg", 
    description: "Weather Data Pipeline with Apache Airflow",
  },
  {
    title: "Weather Data Automation",
    github: "https://github.com/DylanGonzaloFerreyra/Weather-Data-Automation",
    imageUrl: "project_covers/WeatherDataAutomation.jpg",
    description: "This project implements an automated system to collect, store, and manage weather data using the OpenWeatherMap API, MongoDB, and Apache Airflow.",
  },
  {
    title: "SnowPypeLine",
    github: "https://github.com/DylanGonzaloFerreyra/SnowPypeLine",
    imageUrl: "project_covers/SnowPypeline.png",
    description: "This project implements a pipeline for extracting, cleaning, and storing meteorological data. It uses Apache Airflow for orchestration, Pandas for data cleansing, and Snowflake for data cleansing.",
  },
  {
    title: "DBT SnowPipeline",
    github: "https://github.com/DylanGonzaloFerreyra/DBT-SnowPipeline",
    imageUrl: "project_covers/DBTSnowPipeline.jpg",
    description: "This project is responsible for transforming and modeling a dataset using dbt (Data Build Tool)and Snowflake.",
  },
  {
    title: "Weather Flow Project",
    github: "https://github.com/DylanGonzaloFerreyra/Weather-Flow-Project",
    imageUrl: "project_covers/WeatherFlowProject.jpg",
    description: "This project is an automated system for extracting, transform and storing meteorological data using OpenWeatherMap, Apache Spark, Supabase y Airflow",
  },

  
];